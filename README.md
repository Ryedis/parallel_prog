# Отчет лаб.1

## Описание 
В рамках лабораторной работы реализован алгоритм умножения матриц на языке C++. Создан класс Matrix, обеспечивающий загрузку, сохранение и перемножение матриц, а также вывод результата в текстовый файл.

Для верификации корректности и анализа производительности разработан вспомогательный модуль на Python. Он автоматически генерирует квадратные матрицы размера n × n со случайными значениями, сохраняет их в файл, запускает исполняемый файл console.exe, а затем сравнивает результат его выполнения с результатом, полученным с помощью метода numpy.dot(). Также производится логирование времени выполнения операций.

Для визуализации полученных данных строится график зависимости времени выполнения (в наносекундах) от размера матрицы.

## Результат
Результирующий график сохраняется в виде изображения .png.
![График](https://github.com/Ryedis/parallel_prog/blob/master/Lab_1/plot.png)

# Отчет лаб.2

## Описание 
В данной работе была реализована многопоточная версия алгоритма умножения матриц с использованием библиотеки OpenMP. Основные изменения коснулись метода dot(), в котором вычисление строк результирующей матрицы осуществляется параллельно с помощью директивы #pragma omp parallel, а ускорение операций суммирования достигается благодаря векторизации: #pragma omp simd reduction(+:sum).

Результаты тестирования показали увеличение производительности при работе с матрицами минимум в 1,3 раз. Так, при использовании 4 потоков ускорение составило в среднем 1,53 раз.

## Результат
![График](https://github.com/Ryedis/parallel_prog/blob/master/Lab_2/plot.png)
![Сравнение 4 потока](https://github.com/Ryedis/parallel_prog/blob/master/Lab_2/plot_delta.png)

# Отчет лаб.3
В данной лабораторной работе была реализована параллельная версия алгоритма умножения квадратных матриц с использованием библиотеки MPI.

## Общий алгоритм

-   Матрица A делится по строкам между всеми доступными процессами.

    Матрица B рассылается (с помощью MPI_Bcast) всем процессам целиком.

    Каждый процесс выполняет умножение своей части матрицы A на B и возвращает полученные строки результата.

    Сбор итоговой матрицы происходит на процессе с рангом 0.

Для равномерного распределения нагрузки учитывается остаток от деления rows % world_size. Взаимодействие между процессами осуществляется с использованием функций MPI_Send, MPI_Recv и MPI_Bcast.

## Результаты

### Выполнение на собственном компьютере.
![График](https://github.com/Ryedis/parallel_prog/blob/master/Lab_3/MPI_test.png)
Алгоритм показывает ожидаемый прирост на 4 потоках, но использование 12-ти не оправдывает затрат мощностей на уменьшение времени рассчета.

### Работа на суперкомпьютере "Сергей Королев"
![График](https://github.com/Ryedis/parallel_prog/blob//master/Lab_3/korolev/korolev_comprasion.png)
На суперкомпьютере алогритм работает лучше, можно сказать, что прирост улучшения линейно связан с потоками.


# Отчет ЛАБ.4

В данной лабораторной работе была реализована параллельная версия алгоритма умножения квадратных матриц с использованием CUDA.

## Общий алгоритм

- Каждый поток отвечает за рассчет одного элемента финальной матрицы.
- Для покрытия всей матрицы используется CUDA-сетка из блоков потоков

`dim3 block(blockSizeX, blockSizeY);`

`dim3 grid((N + block.x - 1) / block.x, (N + block.y - 1) / block.y);`

Пример расчета: 

- Выделение памяти и загрузка с CPU на GPU

` cudaMalloc((void**)&d_A, size);`

`cudaMalloc((void**)&d_B, size);`

`cudaMalloc((void**)&d_C, size);`

`cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);`

`cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);`

- Далее запускается функция вычисления матрицы `matrixMulCUDA(const float* A, const float* B, float* C, int N) `

- Вычисляются индексы строки и столбца для каждого потока

` int row = blockIdx.y * blockDim.y + threadIdx.y;`

`int col = blockIdx.x * blockDim.x + threadIdx.x;`

где 

`blockIdx.x/y` - Индекс текущего блока по X/Y

`blockDim.x/y` - Размер блока (кол-во потоков в одном блоке)

`threadIdx.x/y` - Индекс потока внутри блока


## Результаты
![Результаты](https://github.com/Ryedis/parallel_prog/blob/master/Lab_4/python_check/result.png)

## Выводы:

Анализ графиков показал, что увеличение размера блоков положительно сказывается на эффективности работы: при более крупных блоках уменьшается их общее число, что снижает накладные расходы на управление. При этом для матриц размером менее 5000 элементов различия между блоками размером 16 и 32 практически не наблюдается. Тем не менее, можно предположить, что при работе с более крупными матрицами эффект от увеличения размера блока станет значительно заметнее.